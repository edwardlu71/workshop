{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meaning of text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import sklearn.datasets as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds has 11314 records of data\n",
      "['DESCR', 'data', 'filenames', 'target', 'target_names']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 'alt.atheism'),\n",
       " (1, 'comp.graphics'),\n",
       " (2, 'comp.os.ms-windows.misc'),\n",
       " (3, 'comp.sys.ibm.pc.hardware'),\n",
       " (4, 'comp.sys.mac.hardware'),\n",
       " (5, 'comp.windows.x'),\n",
       " (6, 'misc.forsale'),\n",
       " (7, 'rec.autos'),\n",
       " (8, 'rec.motorcycles'),\n",
       " (9, 'rec.sport.baseball'),\n",
       " (10, 'rec.sport.hockey'),\n",
       " (11, 'sci.crypt'),\n",
       " (12, 'sci.electronics'),\n",
       " (13, 'sci.med'),\n",
       " (14, 'sci.space'),\n",
       " (15, 'soc.religion.christian'),\n",
       " (16, 'talk.politics.guns'),\n",
       " (17, 'talk.politics.mideast'),\n",
       " (18, 'talk.politics.misc'),\n",
       " (19, 'talk.religion.misc')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = fetch_20newsgroups()\n",
    "print(f\"ds has {len(ds.data)} records of data\")\n",
    "print(dir(ds))\n",
    "\n",
    "#list(zip(list(range(len(ds.target_names))), ds.target_names))\n",
    "list(enumerate(ds.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "rec.autos\n",
      "[\"From: lerxst@wam.umd.edu (where's my thing)\", 'Subject: WHAT car is this!?', 'Nntp-Posting-Host: rac3.wam.umd.edu', 'Organization: University of Maryland, College Park', 'Lines: 15', '', ' I was wondering if anyone out there could enlighten me on this car I saw', 'the other day. It was a 2-door sports car, looked to be from the late 60s/', 'early 70s. It was called a Bricklin. The doors were really small. In addition,', 'the front bumper was separate from the rest of the body. This is ', 'all I know. If anyone can tellme a model name, engine specs, years', 'of production, where this car is made, history, or whatever info you', 'have on this funky looking car, please e-mail.', '', 'Thanks,', '- IL', '   ---- brought to you by your neighborhood Lerxst ----', '', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "# first record\n",
    "print(ds.target[0])\n",
    "print(ds.target_names[ds.target[0]])\n",
    "print(ds.data[0].split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = fetch_20newsgroups(subset='train', categories=selected_categories, shuffle=True, random_state=42)\n",
    "#data_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### try a small data set first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(sample size, dictionary size) = (4, 9)\n",
      "dictionary: ['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 2 0 1 0 1 1 0 1]\n",
      " [1 0 0 1 1 0 1 1 1]\n",
      " [0 1 1 1 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "X = count_vect.fit_transform(samples)\n",
    "print(f\"(sample size, dictionary size) = {X.shape}\")\n",
    "print(f\"dictionary: {count_vect.get_feature_names()}\")\n",
    "\n",
    "# X is a sparse matrix of sample vs dictionary\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### now big one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2257, 35788)\n"
     ]
    }
   ],
   "source": [
    "X_train_counts = count_vect.fit_transform(data_train.data)\n",
    "print(X_train_counts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2257, 35788)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "print(X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# train (fit) the model with the converted count matrix in frequency format and the target (supervised)\n",
    "clf = MultinomialNB().fit(X_train_tfidf, data_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### now use the model on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_new = ['God is love', 'OpenGL on the GPU is fast', 'I am sick', 'My wife is with me']\n",
    "\n",
    "# note: we use transform, not fit_transform\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'God is love' => soc.religion.christian\n",
      "'OpenGL on the GPU is fast' => comp.graphics\n",
      "'I am sick' => sci.med\n",
      "'My wife is with me' => soc.religion.christian\n"
     ]
    }
   ],
   "source": [
    "predicted = clf.predict(X_new_tfidf)\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('%r => %s' % (doc, data_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# single command to train the model\n",
    "text_clf.fit(data_train.data, data_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8348868175765646"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation with test data\n",
    "data_test = fetch_20newsgroups(subset='test', categories=selected_categories, shuffle=True, random_state=42)\n",
    "docs_test = data_test.data\n",
    "predicted = text_clf.predict(docs_test)\n",
    "\n",
    "# test result\n",
    "import numpy as np\n",
    "np.mean(predicted == data_test.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### use a linear support vector machine (SVM), which is widely regarded as one of the best text classification algorithms (although it’s also a bit slower than naïve Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9101198402130493"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(data_train.data, data_train.target)\n",
    "predicted = text_clf.predict(docs_test)\n",
    "np.mean(predicted == data_test.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.95      0.80      0.87       319\n",
      "         comp.graphics       0.87      0.98      0.92       389\n",
      "               sci.med       0.94      0.89      0.91       396\n",
      "soc.religion.christian       0.90      0.95      0.93       398\n",
      "\n",
      "              accuracy                           0.91      1502\n",
      "             macro avg       0.91      0.91      0.91      1502\n",
      "          weighted avg       0.91      0.91      0.91      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(data_test.target, predicted, target_names=data_test.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[256,  11,  16,  36],\n",
       "       [  4, 380,   3,   2],\n",
       "       [  5,  35, 353,   3],\n",
       "       [  5,  11,   4, 378]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix C is such that C_ij is equal to the number of observations known \n",
    "# to be in group i and predicted to be in group j.\n",
    "\n",
    "# we have groups ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "metrics.confusion_matrix(data_test.target, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
